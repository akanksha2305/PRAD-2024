{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-07T19:28:58.542293Z","iopub.status.busy":"2024-04-07T19:28:58.541689Z","iopub.status.idle":"2024-04-07T19:29:06.813137Z","shell.execute_reply":"2024-04-07T19:29:06.811892Z","shell.execute_reply.started":"2024-04-07T19:28:58.542227Z"},"trusted":true},"outputs":[],"source":["# read & manipulate data\n","import pandas as pd \n","import numpy as np\n","import tensorflow as tf\n","\n","# visualisations\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set(style='whitegrid', context='notebook')\n","%matplotlib notebook\n","\n","# misc\n","import random as rn\n","\n","# load the dataset\n","df = pd.read_csv('../input/creditcard.csv')\n","\n","# manual parameters\n","RANDOM_SEED = 42\n","TRAINING_SAMPLE = 200000\n","VALIDATE_SIZE = 0.2\n","\n","# setting random seeds for libraries to ensure reproducibility\n","np.random.seed(RANDOM_SEED)\n","rn.seed(RANDOM_SEED)\n","tf.set_random_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2024-04-07T19:29:06.816400Z","iopub.status.busy":"2024-04-07T19:29:06.815974Z","iopub.status.idle":"2024-04-07T19:29:06.920228Z","shell.execute_reply":"2024-04-07T19:29:06.919149Z","shell.execute_reply.started":"2024-04-07T19:29:06.816320Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>v3</th>\n","      <th>v4</th>\n","      <th>v5</th>\n","      <th>v6</th>\n","      <th>v7</th>\n","      <th>v8</th>\n","      <th>v9</th>\n","      <th>...</th>\n","      <th>v21</th>\n","      <th>v22</th>\n","      <th>v23</th>\n","      <th>v24</th>\n","      <th>v25</th>\n","      <th>v26</th>\n","      <th>v27</th>\n","      <th>v28</th>\n","      <th>amount</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 31 columns</p>\n","</div>"],"text/plain":["   time        v1        v2        v3        v4        v5        v6        v7  \\\n","0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         v8        v9  ...         v21       v22       v23       v24  \\\n","0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n","1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n","2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n","3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n","4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n","\n","        v25       v26       v27       v28  amount  label  \n","0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n","1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n","2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n","3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n","4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n","\n","[5 rows x 31 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df.columns = map(str.lower, df.columns)\n","df.rename(columns={'class': 'label'}, inplace=True)\n","\n","# print first 5 rows to get an initial impression of the data we're dealing with\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:29:06.922137Z","iopub.status.busy":"2024-04-07T19:29:06.921852Z","iopub.status.idle":"2024-04-07T19:29:06.960155Z","shell.execute_reply":"2024-04-07T19:29:06.959322Z","shell.execute_reply.started":"2024-04-07T19:29:06.922089Z"},"trusted":true},"outputs":[],"source":["# add a negligible amount to avoid taking the log of 0\n","df['log10_amount'] = np.log10(df.amount + 0.00001)"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-04-07T19:29:06.961769Z","iopub.status.busy":"2024-04-07T19:29:06.961351Z","iopub.status.idle":"2024-04-07T19:29:07.106134Z","shell.execute_reply":"2024-04-07T19:29:07.105028Z","shell.execute_reply.started":"2024-04-07T19:29:06.961724Z"},"trusted":true},"outputs":[],"source":["# keep the label field at the back\n","df = df[\n","    [col for col in df if col not in ['label', 'log10_amount']] + \n","    ['log10_amount', 'label']\n","]"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2024-04-07T19:29:07.111774Z","iopub.status.busy":"2024-04-07T19:29:07.111390Z","iopub.status.idle":"2024-04-07T19:29:07.274156Z","shell.execute_reply":"2024-04-07T19:29:07.273036Z","shell.execute_reply.started":"2024-04-07T19:29:07.111711Z"},"trusted":true},"outputs":[],"source":["# manual parameter \n","RATIO_TO_FRAUD = 15\n","\n","# dropping redundant columns\n","df = df.drop(['time', 'amount'], axis=1)\n","\n","# splitting by class\n","fraud = df[df.label == 1]\n","clean = df[df.label == 0]\n","\n","# undersample clean transactions\n","clean_undersampled = clean.sample(\n","    int(len(fraud) * RATIO_TO_FRAUD),\n","    random_state=RANDOM_SEED\n",")\n","\n","# concatenate with fraud transactions into a single dataframe\n","visualisation_initial = pd.concat([fraud, clean_undersampled])\n","column_names = list(visualisation_initial.drop('label', axis=1).columns)\n","\n","# isolate features from labels \n","features, labels = visualisation_initial.drop('label', axis=1).values, \\\n","                   visualisation_initial.label.values"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-04-07T19:29:07.278007Z","iopub.status.busy":"2024-04-07T19:29:07.277671Z","iopub.status.idle":"2024-04-07T19:29:07.284312Z","shell.execute_reply":"2024-04-07T19:29:07.283277Z","shell.execute_reply.started":"2024-04-07T19:29:07.277955Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The non-fraud dataset has been undersampled from 284,315 to 7,380.\n","This represents a ratio of 15:1 to fraud.\n"]}],"source":["print(f\"\"\"The non-fraud dataset has been undersampled from {len(clean):,} to {len(clean_undersampled):,}.\n","This represents a ratio of {RATIO_TO_FRAUD}:1 to fraud.\"\"\")"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-04-07T19:30:35.689517Z","iopub.status.busy":"2024-04-07T19:30:35.689021Z","iopub.status.idle":"2024-04-07T19:30:35.694466Z","shell.execute_reply":"2024-04-07T19:30:35.693731Z","shell.execute_reply.started":"2024-04-07T19:30:35.689469Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the datasets:\n","    clean (rows, cols) = (284315, 30)\n","    fraud (rows, cols) = (492, 30)\n"]}],"source":["print(f\"\"\"Shape of the datasets:\n","    clean (rows, cols) = {clean.shape}\n","    fraud (rows, cols) = {fraud.shape}\"\"\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:35.696334Z","iopub.status.busy":"2024-04-07T19:30:35.695824Z","iopub.status.idle":"2024-04-07T19:30:35.984226Z","shell.execute_reply":"2024-04-07T19:30:35.983062Z","shell.execute_reply.started":"2024-04-07T19:30:35.696285Z"},"trusted":true},"outputs":[],"source":["# shuffle our training set\n","clean = clean.sample(frac=1).reset_index(drop=True)\n","\n","# training set: exlusively non-fraud transactions\n","X_train = clean.iloc[:TRAINING_SAMPLE].drop('label', axis=1)\n","\n","# testing  set: the remaining non-fraud + all the fraud \n","X_test = clean.iloc[TRAINING_SAMPLE:].append(fraud).sample(frac=1)"]},{"cell_type":"code","execution_count":11,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-04-07T19:30:35.986195Z","iopub.status.busy":"2024-04-07T19:30:35.985843Z","iopub.status.idle":"2024-04-07T19:30:35.995061Z","shell.execute_reply":"2024-04-07T19:30:35.993782Z","shell.execute_reply.started":"2024-04-07T19:30:35.986134Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Our testing set is composed as follows:\n","\n","0    84315\n","1      492\n","Name: label, dtype: int64\n"]}],"source":["print(f\"\"\"Our testing set is composed as follows:\n","\n","{X_test.label.value_counts()}\"\"\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:35.997616Z","iopub.status.busy":"2024-04-07T19:30:35.997129Z","iopub.status.idle":"2024-04-07T19:30:36.090987Z","shell.execute_reply":"2024-04-07T19:30:36.090001Z","shell.execute_reply.started":"2024-04-07T19:30:35.997526Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# train // validate - no labels since they're all clean anyway\n","X_train, X_validate = train_test_split(X_train, \n","                                       test_size=VALIDATE_SIZE, \n","                                       random_state=RANDOM_SEED)\n","\n","# manually splitting the labels from the test df\n","X_test, y_test = X_test.drop('label', axis=1).values, X_test.label.values"]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-04-07T19:30:36.093626Z","iopub.status.busy":"2024-04-07T19:30:36.093192Z","iopub.status.idle":"2024-04-07T19:30:36.100388Z","shell.execute_reply":"2024-04-07T19:30:36.099134Z","shell.execute_reply.started":"2024-04-07T19:30:36.093538Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the datasets:\n","    training (rows, cols) = (160000, 29)\n","    validate (rows, cols) = (40000, 29)\n","    holdout  (rows, cols) = (84807, 29)\n"]}],"source":["print(f\"\"\"Shape of the datasets:\n","    training (rows, cols) = {X_train.shape}\n","    validate (rows, cols) = {X_validate.shape}\n","    holdout  (rows, cols) = {X_test.shape}\"\"\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:36.102634Z","iopub.status.busy":"2024-04-07T19:30:36.102236Z","iopub.status.idle":"2024-04-07T19:30:36.113812Z","shell.execute_reply":"2024-04-07T19:30:36.112723Z","shell.execute_reply.started":"2024-04-07T19:30:36.102567Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import Normalizer, MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","\n","# configure our pipeline\n","pipeline = Pipeline([('normalizer', Normalizer()),\n","                     ('scaler', MinMaxScaler())])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:36.116224Z","iopub.status.busy":"2024-04-07T19:30:36.115757Z","iopub.status.idle":"2024-04-07T19:30:36.211326Z","shell.execute_reply":"2024-04-07T19:30:36.209491Z","shell.execute_reply.started":"2024-04-07T19:30:36.116148Z"},"trusted":true},"outputs":[],"source":["# get normalization parameters by fitting to the training data\n","pipeline.fit(X_train)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:36.213945Z","iopub.status.busy":"2024-04-07T19:30:36.213414Z","iopub.status.idle":"2024-04-07T19:30:36.304978Z","shell.execute_reply":"2024-04-07T19:30:36.303844Z","shell.execute_reply.started":"2024-04-07T19:30:36.213856Z"},"trusted":true},"outputs":[],"source":["# transform the training and validation data with these parameters\n","X_train_transformed = pipeline.transform(X_train)\n","X_validate_transformed = pipeline.transform(X_validate)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:54.233502Z","iopub.status.busy":"2024-04-07T19:30:54.233051Z","iopub.status.idle":"2024-04-07T19:30:54.565510Z","shell.execute_reply":"2024-04-07T19:30:54.564478Z","shell.execute_reply.started":"2024-04-07T19:30:54.233427Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 29)                870       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 16)                480       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 8)                 136       \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 36        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 2)                 10        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 4)                 12        \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 8)                 40        \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 16)                144       \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 29)                493       \n","=================================================================\n","Total params: 2,221\n","Trainable params: 2,221\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# data dimensions // hyperparameters \n","input_dim = X_train_transformed.shape[1]\n","BATCH_SIZE = 256\n","EPOCHS = 100\n","\n","# https://keras.io/layers/core/\n","autoencoder = tf.keras.models.Sequential([\n","    \n","    # deconstruct / encode\n","    tf.keras.layers.Dense(input_dim, activation='elu', input_shape=(input_dim, )), \n","    tf.keras.layers.Dense(16, activation='elu'),\n","    tf.keras.layers.Dense(8, activation='elu'),\n","    tf.keras.layers.Dense(4, activation='elu'),\n","    tf.keras.layers.Dense(2, activation='elu'),\n","    \n","    # reconstruction / decode\n","    tf.keras.layers.Dense(4, activation='elu'),\n","    tf.keras.layers.Dense(8, activation='elu'),\n","    tf.keras.layers.Dense(16, activation='elu'),\n","    tf.keras.layers.Dense(input_dim, activation='elu')\n","    \n","])\n","\n","# https://keras.io/api/models/model_training_apis/\n","autoencoder.compile(optimizer=\"adam\", \n","                    loss=\"mse\",\n","                    metrics=[\"acc\"])\n","\n","# print an overview of our model\n","autoencoder.summary();"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:54.567736Z","iopub.status.busy":"2024-04-07T19:30:54.567294Z","iopub.status.idle":"2024-04-07T19:30:54.579361Z","shell.execute_reply":"2024-04-07T19:30:54.578214Z","shell.execute_reply.started":"2024-04-07T19:30:54.567659Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","\n","# current date and time\n","yyyymmddHHMM = datetime.now().strftime('%Y%m%d%H%M')\n","\n","# new folder for a new run\n","log_subdir = f'{yyyymmddHHMM}_batch{BATCH_SIZE}_layers{len(autoencoder.layers)}'\n","\n","# define our early stopping\n","early_stop = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0.0001,\n","    patience=10,\n","    verbose=1, \n","    mode='min',\n","    restore_best_weights=True\n",")\n","\n","save_model = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='autoencoder_best_weights.hdf5',\n","    save_best_only=True,\n","    monitor='val_loss',\n","    verbose=0,\n","    mode='min'\n",")\n","\n","tensorboard = tf.keras.callbacks.TensorBoard(\n","    f'logs/{log_subdir}',\n","    batch_size=BATCH_SIZE,\n","    update_freq='batch'\n",")\n","\n","# callbacks argument only takes a list\n","cb = [early_stop, save_model, tensorboard]"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:30:54.581307Z","iopub.status.busy":"2024-04-07T19:30:54.581002Z","iopub.status.idle":"2024-04-07T19:35:04.740296Z","shell.execute_reply":"2024-04-07T19:35:04.738960Z","shell.execute_reply.started":"2024-04-07T19:30:54.581259Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 160000 samples, validate on 40000 samples\n","Epoch 1/100\n","160000/160000 [==============================] - 3s 19us/sample - loss: 0.0299 - acc: 0.2403 - val_loss: 0.0157 - val_acc: 0.3120\n","Epoch 2/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0151 - acc: 0.3341 - val_loss: 0.0148 - val_acc: 0.3444\n","Epoch 3/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0146 - acc: 0.3484 - val_loss: 0.0145 - val_acc: 0.3454\n","Epoch 4/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0144 - acc: 0.3490 - val_loss: 0.0143 - val_acc: 0.3532\n","Epoch 5/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0142 - acc: 0.3502 - val_loss: 0.0142 - val_acc: 0.3522\n","Epoch 6/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0141 - acc: 0.3453 - val_loss: 0.0140 - val_acc: 0.3406\n","Epoch 7/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0139 - acc: 0.3426 - val_loss: 0.0139 - val_acc: 0.3332\n","Epoch 8/100\n","160000/160000 [==============================] - 3s 18us/sample - loss: 0.0138 - acc: 0.3415 - val_loss: 0.0138 - val_acc: 0.3424\n","Epoch 9/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0137 - acc: 0.3469 - val_loss: 0.0137 - val_acc: 0.3496\n","Epoch 10/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0137 - acc: 0.3558 - val_loss: 0.0137 - val_acc: 0.3613\n","Epoch 11/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0136 - acc: 0.3651 - val_loss: 0.0136 - val_acc: 0.3589\n","Epoch 12/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0135 - acc: 0.3708 - val_loss: 0.0134 - val_acc: 0.3729\n","Epoch 13/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0131 - acc: 0.3690 - val_loss: 0.0129 - val_acc: 0.3633\n","Epoch 14/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0128 - acc: 0.3639 - val_loss: 0.0128 - val_acc: 0.3548\n","Epoch 15/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0127 - acc: 0.3569 - val_loss: 0.0127 - val_acc: 0.3461\n","Epoch 16/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0126 - acc: 0.3519 - val_loss: 0.0126 - val_acc: 0.3438\n","Epoch 17/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0125 - acc: 0.3461 - val_loss: 0.0125 - val_acc: 0.3406\n","Epoch 18/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0124 - acc: 0.3430 - val_loss: 0.0124 - val_acc: 0.3355\n","Epoch 19/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0123 - acc: 0.3428 - val_loss: 0.0122 - val_acc: 0.3463\n","Epoch 20/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0122 - acc: 0.3498 - val_loss: 0.0121 - val_acc: 0.3508\n","Epoch 21/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0121 - acc: 0.3568 - val_loss: 0.0121 - val_acc: 0.3569\n","Epoch 22/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0121 - acc: 0.3618 - val_loss: 0.0121 - val_acc: 0.3616\n","Epoch 23/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0120 - acc: 0.3645 - val_loss: 0.0120 - val_acc: 0.3660\n","Epoch 24/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0120 - acc: 0.3660 - val_loss: 0.0120 - val_acc: 0.3673\n","Epoch 25/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0119 - acc: 0.3666 - val_loss: 0.0119 - val_acc: 0.3646\n","Epoch 26/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0119 - acc: 0.3670 - val_loss: 0.0119 - val_acc: 0.3618\n","Epoch 27/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0118 - acc: 0.3708 - val_loss: 0.0118 - val_acc: 0.3612\n","Epoch 28/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0118 - acc: 0.3764 - val_loss: 0.0118 - val_acc: 0.3794\n","Epoch 29/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0117 - acc: 0.3791 - val_loss: 0.0117 - val_acc: 0.3681\n","Epoch 30/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0117 - acc: 0.3795 - val_loss: 0.0117 - val_acc: 0.3735\n","Epoch 31/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0116 - acc: 0.3785 - val_loss: 0.0116 - val_acc: 0.3785\n","Epoch 32/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0116 - acc: 0.3786 - val_loss: 0.0116 - val_acc: 0.3760\n","Epoch 33/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0115 - acc: 0.3789 - val_loss: 0.0115 - val_acc: 0.3815\n","Epoch 34/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0114 - acc: 0.3805 - val_loss: 0.0114 - val_acc: 0.3801\n","Epoch 35/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0114 - acc: 0.3820 - val_loss: 0.0114 - val_acc: 0.3831\n","Epoch 36/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0113 - acc: 0.3821 - val_loss: 0.0113 - val_acc: 0.3825\n","Epoch 37/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0113 - acc: 0.3825 - val_loss: 0.0113 - val_acc: 0.3812\n","Epoch 38/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0113 - acc: 0.3817 - val_loss: 0.0113 - val_acc: 0.3841\n","Epoch 39/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0112 - acc: 0.3812 - val_loss: 0.0112 - val_acc: 0.3790\n","Epoch 40/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0112 - acc: 0.3811 - val_loss: 0.0112 - val_acc: 0.3794\n","Epoch 41/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0112 - acc: 0.3804 - val_loss: 0.0112 - val_acc: 0.3796\n","Epoch 42/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0112 - acc: 0.3803 - val_loss: 0.0112 - val_acc: 0.3811\n","Epoch 43/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0111 - acc: 0.3803 - val_loss: 0.0111 - val_acc: 0.3798\n","Epoch 44/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0111 - acc: 0.3787 - val_loss: 0.0111 - val_acc: 0.3787\n","Epoch 45/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0111 - acc: 0.3790 - val_loss: 0.0111 - val_acc: 0.3715\n","Epoch 46/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0111 - acc: 0.3788 - val_loss: 0.0110 - val_acc: 0.3799\n","Epoch 47/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0110 - acc: 0.3785 - val_loss: 0.0110 - val_acc: 0.3808\n","Epoch 48/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0110 - acc: 0.3780 - val_loss: 0.0110 - val_acc: 0.3771\n","Epoch 49/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0110 - acc: 0.3778 - val_loss: 0.0110 - val_acc: 0.3753\n","Epoch 50/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0109 - acc: 0.3767 - val_loss: 0.0109 - val_acc: 0.3775\n","Epoch 51/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0109 - acc: 0.3771 - val_loss: 0.0109 - val_acc: 0.3747\n","Epoch 52/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0108 - acc: 0.3768 - val_loss: 0.0109 - val_acc: 0.3763\n","Epoch 53/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0108 - acc: 0.3765 - val_loss: 0.0108 - val_acc: 0.3738\n","Epoch 54/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0108 - acc: 0.3769 - val_loss: 0.0108 - val_acc: 0.3789\n","Epoch 55/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0108 - acc: 0.3778 - val_loss: 0.0108 - val_acc: 0.3744\n","Epoch 56/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0107 - acc: 0.3783 - val_loss: 0.0107 - val_acc: 0.3767\n","Epoch 57/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0107 - acc: 0.3781 - val_loss: 0.0107 - val_acc: 0.3753\n","Epoch 58/100\n","160000/160000 [==============================] - 2s 14us/sample - loss: 0.0107 - acc: 0.3790 - val_loss: 0.0107 - val_acc: 0.3754\n","Epoch 59/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0106 - acc: 0.3790 - val_loss: 0.0106 - val_acc: 0.3760\n","Epoch 60/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0106 - acc: 0.3795 - val_loss: 0.0106 - val_acc: 0.3774\n","Epoch 61/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0106 - acc: 0.3791 - val_loss: 0.0106 - val_acc: 0.3801\n","Epoch 62/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0106 - acc: 0.3798 - val_loss: 0.0106 - val_acc: 0.3774\n","Epoch 63/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0105 - acc: 0.3792 - val_loss: 0.0105 - val_acc: 0.3736\n","Epoch 64/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0105 - acc: 0.3805 - val_loss: 0.0105 - val_acc: 0.3748\n","Epoch 65/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0105 - acc: 0.3800 - val_loss: 0.0105 - val_acc: 0.3770\n","Epoch 66/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0104 - acc: 0.3803 - val_loss: 0.0105 - val_acc: 0.3807\n","Epoch 67/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0104 - acc: 0.3796 - val_loss: 0.0104 - val_acc: 0.3720\n","Epoch 68/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0104 - acc: 0.3791 - val_loss: 0.0104 - val_acc: 0.3738\n","Epoch 69/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0103 - acc: 0.3792 - val_loss: 0.0104 - val_acc: 0.3744\n","Epoch 70/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0103 - acc: 0.3782 - val_loss: 0.0103 - val_acc: 0.3722\n","Epoch 71/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0103 - acc: 0.3778 - val_loss: 0.0103 - val_acc: 0.3692\n","Epoch 72/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0102 - acc: 0.3768 - val_loss: 0.0103 - val_acc: 0.3713\n","Epoch 73/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0102 - acc: 0.3768 - val_loss: 0.0102 - val_acc: 0.3748\n","Epoch 74/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0102 - acc: 0.3757 - val_loss: 0.0102 - val_acc: 0.3722\n","Epoch 75/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0101 - acc: 0.3752 - val_loss: 0.0101 - val_acc: 0.3760\n","Epoch 76/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0101 - acc: 0.3758 - val_loss: 0.0101 - val_acc: 0.3720\n","Epoch 77/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0101 - acc: 0.3754 - val_loss: 0.0101 - val_acc: 0.3661\n","Epoch 78/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0100 - acc: 0.3756 - val_loss: 0.0100 - val_acc: 0.3735\n","Epoch 79/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0100 - acc: 0.3764 - val_loss: 0.0100 - val_acc: 0.3735\n","Epoch 80/100\n","160000/160000 [==============================] - 3s 17us/sample - loss: 0.0100 - acc: 0.3769 - val_loss: 0.0100 - val_acc: 0.3792\n","Epoch 81/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0100 - acc: 0.3776 - val_loss: 0.0100 - val_acc: 0.3765\n","Epoch 82/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0099 - acc: 0.3780 - val_loss: 0.0099 - val_acc: 0.3772\n","Epoch 83/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0099 - acc: 0.3790 - val_loss: 0.0099 - val_acc: 0.3726\n","Epoch 84/100\n","160000/160000 [==============================] - 3s 19us/sample - loss: 0.0099 - acc: 0.3797 - val_loss: 0.0099 - val_acc: 0.3820\n","Epoch 85/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0099 - acc: 0.3800 - val_loss: 0.0099 - val_acc: 0.3760\n","Epoch 86/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0099 - acc: 0.3808 - val_loss: 0.0099 - val_acc: 0.3796\n","Epoch 87/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0098 - acc: 0.3817 - val_loss: 0.0099 - val_acc: 0.3777\n","Epoch 88/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0098 - acc: 0.3819 - val_loss: 0.0098 - val_acc: 0.3792\n","Epoch 89/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0098 - acc: 0.3829 - val_loss: 0.0099 - val_acc: 0.3780\n","Epoch 90/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0098 - acc: 0.3836 - val_loss: 0.0098 - val_acc: 0.3780\n","Epoch 91/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0098 - acc: 0.3847 - val_loss: 0.0098 - val_acc: 0.3754\n","Epoch 92/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0098 - acc: 0.3855 - val_loss: 0.0098 - val_acc: 0.3840\n","Epoch 93/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0098 - acc: 0.3863 - val_loss: 0.0098 - val_acc: 0.3839\n","Epoch 94/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0097 - acc: 0.3866 - val_loss: 0.0098 - val_acc: 0.3849\n","Epoch 95/100\n","160000/160000 [==============================] - 2s 16us/sample - loss: 0.0097 - acc: 0.3872 - val_loss: 0.0097 - val_acc: 0.3873\n","Epoch 96/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0097 - acc: 0.3882 - val_loss: 0.0098 - val_acc: 0.3752\n","Epoch 97/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0097 - acc: 0.3889 - val_loss: 0.0097 - val_acc: 0.3849\n","Epoch 98/100\n","160000/160000 [==============================] - 2s 15us/sample - loss: 0.0097 - acc: 0.3891 - val_loss: 0.0097 - val_acc: 0.3822\n","Epoch 99/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0097 - acc: 0.3897 - val_loss: 0.0097 - val_acc: 0.3907\n","Epoch 100/100\n","160000/160000 [==============================] - 3s 16us/sample - loss: 0.0097 - acc: 0.3902 - val_loss: 0.0097 - val_acc: 0.3789\n"]}],"source":["history = autoencoder.fit(\n","    X_train_transformed, X_train_transformed,\n","    shuffle=True,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    callbacks=cb,\n","    validation_data=(X_validate_transformed, X_validate_transformed)\n",");"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:35:04.742751Z","iopub.status.busy":"2024-04-07T19:35:04.742302Z","iopub.status.idle":"2024-04-07T19:35:06.341832Z","shell.execute_reply":"2024-04-07T19:35:06.340846Z","shell.execute_reply.started":"2024-04-07T19:35:04.742676Z"},"trusted":true},"outputs":[],"source":["# transform the test set with the pipeline fitted to the training set\n","X_test_transformed = pipeline.transform(X_test)\n","\n","# pass the transformed test set through the autoencoder to get the reconstructed result\n","reconstructions = autoencoder.predict(X_test_transformed)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:35:06.343711Z","iopub.status.busy":"2024-04-07T19:35:06.343361Z","iopub.status.idle":"2024-04-07T19:35:06.396632Z","shell.execute_reply":"2024-04-07T19:35:06.395709Z","shell.execute_reply.started":"2024-04-07T19:35:06.343648Z"},"trusted":true},"outputs":[],"source":["# calculating the mean squared error reconstruction loss per row in the numpy array\n","mse = np.mean(np.power(X_test_transformed - reconstructions, 2), axis=1)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T19:35:06.921700Z","iopub.status.busy":"2024-04-07T19:35:06.921110Z","iopub.status.idle":"2024-04-07T19:35:06.934382Z","shell.execute_reply":"2024-04-07T19:35:06.933238Z","shell.execute_reply.started":"2024-04-07T19:35:06.921490Z"},"trusted":true},"outputs":[],"source":["THRESHOLD = 3\n","\n","def mad_score(points):\n","    \"\"\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm \"\"\"\n","    m = np.median(points)\n","    ad = np.abs(points - m)\n","    mad = np.median(ad)\n","    \n","    return 0.6745 * ad / mad\n","\n","z_scores = mad_score(mse)\n","outliers = z_scores > THRESHOLD"]},{"cell_type":"code","execution_count":27,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-04-07T19:35:06.936683Z","iopub.status.busy":"2024-04-07T19:35:06.936232Z","iopub.status.idle":"2024-04-07T19:35:06.943582Z","shell.execute_reply":"2024-04-07T19:35:06.942664Z","shell.execute_reply.started":"2024-04-07T19:35:06.936607Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Detected 1,647 outliers in a total of 84,807 transactions [1.94%].\n"]}],"source":["print(f\"Detected {np.sum(outliers):,} outliers in a total of {np.size(z_scores):,} transactions [{np.sum(outliers)/np.size(z_scores):.2%}].\")"]},{"cell_type":"code","execution_count":28,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2024-04-07T19:35:06.945659Z","iopub.status.busy":"2024-04-07T19:35:06.945368Z","iopub.status.idle":"2024-04-07T19:35:07.373209Z","shell.execute_reply":"2024-04-07T19:35:07.372079Z","shell.execute_reply.started":"2024-04-07T19:35:06.945610Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import (confusion_matrix, \n","                             precision_recall_curve)\n","\n","# get (mis)classification\n","cm = confusion_matrix(y_test, outliers)\n","\n","# true/false positives/negatives\n","(tn, fp, \n"," fn, tp) = cm.flatten()"]},{"cell_type":"code","execution_count":29,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-04-07T19:35:07.375370Z","iopub.status.busy":"2024-04-07T19:35:07.374978Z","iopub.status.idle":"2024-04-07T19:35:07.381798Z","shell.execute_reply":"2024-04-07T19:35:07.380852Z","shell.execute_reply.started":"2024-04-07T19:35:07.375303Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The classifications using the MAD method with threshold=3 are as follows:\n","[[83027  1288]\n"," [  133   359]]\n","\n","% of transactions labeled as fraud that were correct (precision): 359/(1288+359) = 21.80%\n","% of fraudulent transactions were caught succesfully (recall):    359/(133+359) = 72.97%\n"]}],"source":["print(f\"\"\"The classifications using the MAD method with threshold={THRESHOLD} are as follows:\n","{cm}\n","\n","% of transactions labeled as fraud that were correct (precision): {tp}/({fp}+{tp}) = {tp/(fp+tp):.2%}\n","% of fraudulent transactions were caught succesfully (recall):    {tp}/({fn}+{tp}) = {tp/(fn+tp):.2%}\"\"\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":310,"sourceId":23498,"sourceType":"datasetVersion"}],"dockerImageVersionId":28755,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
